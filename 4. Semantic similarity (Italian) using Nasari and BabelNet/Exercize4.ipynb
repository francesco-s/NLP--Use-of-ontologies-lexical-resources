{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1c26431-b355-4bec-9186-c9416807f983",
   "metadata": {},
   "source": [
    "## Exercize 4\n",
    "### Semantic similarity (Italian) using Nasari and BabelNet\n",
    "#### Francesco Sannicola"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66a005e5-eec2-4a05-b28b-bb3311e09824",
   "metadata": {},
   "source": [
    "Method shared able to return a interval depending of my surname."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6495cfd9-fa3b-46e9-adc1-b647ec35e83c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sannicola      :\tcoppie nell'intervallo 351-400\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "def get_range(surname):\n",
    "    nof_elements = 500\n",
    "    base_idx = (abs(int(hashlib.sha512(surname.encode('utf-8')).hexdigest(), 16)) % 10)\n",
    "    idx_intervallo = base_idx * 50+1\n",
    "    return idx_intervallo\n",
    " \n",
    "\n",
    "input_name = \"sannicola\"\n",
    "\n",
    "values = []\n",
    "sx = get_range(input_name)\n",
    "values.append(sx)\n",
    "dx = sx+50-1\n",
    "intervallo = \"\" + str(sx) + \"-\" + str(dx)\n",
    "print('{:15}:\\tcoppie nell\\'intervallo {}'.format(input_name, intervallo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df45e8a8-c1ee-430d-a9cd-0bf3d2b5f888",
   "metadata": {},
   "source": [
    "Csv library useful to read all the files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2743eee0-8a92-4b8d-adb6-ce112e036168",
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da6a9328-0ea9-4d7c-934d-81f1f6cf1a9c",
   "metadata": {},
   "source": [
    "Simply reads a tsv handwritten (me and my sister) annotation file.\n",
    "- 0: totally dissimilar\n",
    "- 1: dissimilar\n",
    "- 2: Slightly similar\n",
    "- 3: Similar\n",
    "- 4: Very similar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8e30b415-3083-4e4f-a4a5-7ad87332bbe4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_annotation_file(file):\n",
    "    res = []\n",
    "    \n",
    "    with open(file) as fd:\n",
    "        rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for row in rd:\n",
    "            res.append(row)\n",
    "    \n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd69edfe-1b5c-4321-b4bf-602d2621d910",
   "metadata": {},
   "source": [
    "Read a embedded version of Nasari and returns a dictionary like {bn:xxxxxx : [score1, score2]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4eddc565-6401-471f-8bcb-fa602fe0f6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_nasari_dict(file):\n",
    "    nasari_dict = dict()\n",
    "    \n",
    "    with open(file) as fd:\n",
    "        rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for row in rd:\n",
    "            row_splitted=row[0].split('_')[0]\n",
    "            nasari_dict[row_splitted] = row[1:]\n",
    "    \n",
    "    return nasari_dict"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dbe9689-f7b3-4d1f-95af-96a4fd6cf06d",
   "metadata": {},
   "source": [
    "The above method reads a file containing italian's terms associated with a list of BabelID.\n",
    "\n",
    "Obtain a dict of {word_it: [bn:xxxxxx1, bn:xxxxxx2]} tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dddc6750-1e51-47f7-abea-7f04420409ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_italian_synsets(file):\n",
    "\n",
    "    italian_synset = dict()\n",
    "    word = \"\"\n",
    "    \n",
    "    with open(file, 'r', encoding=\"utf8\") as fd:\n",
    "        \n",
    "        rd = csv.reader(fd, delimiter=\"\\t\", quotechar='\"')\n",
    "        for row in rd:\n",
    "            if row[0][0] == \"#\":\n",
    "                word = row[0][1:].lower()\n",
    "                italian_synset[word] = []\n",
    "            else:\n",
    "                italian_synset[word].extend(row)\n",
    "                \n",
    "    return italian_synset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b7d7696d-35c8-4edb-b182-d1117683bf67",
   "metadata": {},
   "source": [
    "Import cosine similarity metric from sklearn library and numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "233cbb2e-b9e1-4877-b969-1542cfc067f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e429a3b5-34ba-4a33-8d29-109c2dd28e1a",
   "metadata": {},
   "source": [
    "Compute similarity (cosine) for two lists BabelIDs given nasari vectors as dict."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f09f524b-8425-4298-aaf0-d295133411b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_vector(nasari_dict, bab_ids_word1, bab_ids_word2):\n",
    "    \"\"\"\n",
    "    :param nasari_dict: NASARI dictionary\n",
    "    :param babel_id_word1: list of BabelID\n",
    "    :param babel_id_word2: list of BabelID\n",
    "    \"\"\"\n",
    "\n",
    "    best_senses = (None, None)\n",
    "    max_similarity = 0\n",
    "\n",
    "    \n",
    "    for b_id1 in bab_ids_word1:\n",
    "        for b_id2 in bab_ids_word2:\n",
    "            # Check first there are entry in nasary dict with this babelnet ids\n",
    "            if b_id1 in nasari_dict.keys():\n",
    "                if b_id2 in nasari_dict.keys():\n",
    "                    \n",
    "                    # Obtain nasari dict from babelnet id and reshape to fit all in 1 row\n",
    "                    v1 = np.array(nasari_dict[b_id1]).reshape(1, len(nasari_dict[b_id1]))\n",
    "                    v2 = np.array(nasari_dict[b_id2]).reshape(1, len(nasari_dict[b_id2]))\n",
    "\n",
    "                    # use cosine similarity of sklearn\n",
    "                    similarity = cosine_similarity(v1, v2)[0]\n",
    "                    \n",
    "                    # save only the 2 best babelnet IDs\n",
    "                    if similarity > max_similarity:\n",
    "                        max_similarity = similarity\n",
    "                        best_senses = (b_id1, b_id2)\n",
    "\n",
    "    return best_senses, max_similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "be48d0dd-3ab3-4fe3-8163-387e18df5a3f",
   "metadata": {},
   "source": [
    "Get lists and dicts of scores, golds, targets, synsets and nasari vectors from files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dcf1b0eb-f180-424a-90b6-0d0ecb38f520",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read all files\n",
    "annotation1 = read_annotation_file(\"utils/data351-400.tsv\")\n",
    "annotation2 = read_annotation_file(\"utils/data351-400-sister.tsv\")\n",
    "\n",
    "nasari_dict = get_nasari_dict(\"utils/mini_NASARI.tsv\")\n",
    "\n",
    "gold = get_italian_synsets(\"utils/SemEval17_IT_senses2synsets.txt\")\n",
    "\n",
    "base, target = [], []\n",
    "annotation1_score, annotation2_score = [], []\n",
    "\n",
    "# Get all couples and the semantic similarity scores (mine and my sister)\n",
    "for el in annotation1:\n",
    "    base.append(el[0].lower())\n",
    "    target.append(el[1].lower())\n",
    "    annotation1_score.append(float(el[2]))\n",
    "    \n",
    "for el in annotation2:\n",
    "    annotation2_score.append(float(el[2]))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9648862f-92b3-4fd2-a4b9-f4bbacb0d34e",
   "metadata": {},
   "source": [
    "Import two evaluation metrics form scipy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0108ce52-358d-4527-9b33-ff274175d57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import pearsonr, spearmanr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b26610fe-6e1b-4878-9ea4-f5e8f93370ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Spearman and Person scores between human annotations\n",
      "\n",
      "Spearman:  0.917764855859008\n",
      "Pearson:  0.9353309809796745\n",
      "\n",
      "\n",
      "Spearman and Person scores between human annotation and scores computed\n",
      "\n",
      "\u001b[1mAnnotation 1:\u001b[0m\n",
      "Spearman:  0.47012559867068004\n",
      "Pearson:  0.607574621930617\n",
      "\n",
      "\u001b[1mAnnotation 2:\u001b[0m\n",
      "Spearman:  0.4110861020947786\n",
      "Pearson:  0.550105156422494\n"
     ]
    }
   ],
   "source": [
    "golds_score = []\n",
    "\n",
    "for i in range(0, len(annotation1)):\n",
    "    _ , score = cosine_similarity_vector(nasari_dict, gold[base[i]], gold[target[i]])\n",
    "    golds_score.append(float(score))\n",
    "\n",
    "    \n",
    "# inter rate agreement between first and second annotation\n",
    "print(\"Spearman and Person scores between human annotations\\n\")\n",
    "\n",
    "print(\"Spearman: \", spearmanr(annotation1_score, annotation2_score)[0])\n",
    "print(\"Pearson: \", pearsonr(annotation1_score, annotation2_score)[0])\n",
    "\n",
    "# Comparison between my_score and gold score\n",
    "print(\"\\n\\nSpearman and Person scores between human annotation and scores computed\")\n",
    "\n",
    "print(\"\\n\"+'\\033[1m' + \"Annotation 1:\" + '\\033[0m')\n",
    "print(\"Spearman: \", pearsonr(golds_score, annotation1_score)[0])\n",
    "print(\"Pearson: \", spearmanr(golds_score, annotation1_score)[0])\n",
    "\n",
    "print(\"\\n\"+'\\033[1m' + \"Annotation 2:\" + '\\033[0m')\n",
    "print(\"Spearman: \", pearsonr(golds_score, annotation2_score)[0])\n",
    "print(\"Pearson: \", spearmanr(golds_score, annotation2_score)[0])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c73b188a-f39f-4f93-8000-572f3787ba1a",
   "metadata": {},
   "source": [
    "Import another metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "500506ca-f4af-47d4-8c0e-0b2effecdd7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import cohen_kappa_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ef46c-2422-4b95-a585-b614cd1daebb",
   "metadata": {},
   "source": [
    "Calculate annotation agreement with Cohen score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "7fb118a9-16f8-42ef-835f-01045190fe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cohen score between human annotations\n",
      "\n",
      "Cohen:  0.5841995841995842\n"
     ]
    }
   ],
   "source": [
    "int_annotation1_score = [int(i) for i in annotation1_score]\n",
    "int_annotation2_score = [int(i) for i in annotation2_score]\n",
    "\n",
    "cohen_score = cohen_kappa_score(int_annotation1_score, int_annotation2_score)\n",
    "print(\"Cohen score between human annotations\\n\")\n",
    "print(\"Cohen: \", cohen_score)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1dceb03-3878-4db8-b34e-94670b21f14a",
   "metadata": {},
   "source": [
    "Next goal is to find which is the senses used for similarity judgment.\n",
    "\n",
    "The next method calls BabelNet HTTP API with a babelnet synset ID as a parameter.\n",
    "\n",
    "It returns three terms associated to the given synset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18325ec6-9797-49b3-90ee-fa90328f3c6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import requests\n",
    "\n",
    "def get_synset_terms_HTTP(babel_id):\n",
    "    \"\"\"\n",
    "    :param babel_id: sense's BabelID\n",
    "    \"\"\"\n",
    "\n",
    "    url = \"https://babelnet.io/v5/getSynset\"\n",
    "    params = {\n",
    "        \"id\": babel_id,\n",
    "        \"key\": \"fd6e7223-95d6-40ce-96b4-8d3bf9123200\",\n",
    "        \"targetLang\": \"IT\"\n",
    "    }\n",
    "\n",
    "    # Perform the request\n",
    "    req = requests.get(url=url, params=params)\n",
    "    \n",
    "    # Obtain response in json\n",
    "    response = req.json()\n",
    "\n",
    "    i, limit = 0, 0\n",
    "    terms = []\n",
    "    \n",
    "    while i < len(response[\"senses\"]) and limit < 3:\n",
    "        \n",
    "        # Obtain a term associated to the given synset. After do some string processing.\n",
    "        term = response[\"senses\"][i][\"properties\"][\"fullLemma\"]\n",
    "        term = re.sub('\\_', ' ', term)\n",
    "        term = term.lower()\n",
    "\n",
    "        if term not in terms:\n",
    "            terms.append(term)\n",
    "            limit += 1\n",
    "\n",
    "        i += 1\n",
    "\n",
    "    if len(terms) == 0:\n",
    "        return \"Null\"\n",
    "    else:\n",
    "        return terms"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07faf5a-63c9-4948-8fdb-7993c58fe8f8",
   "metadata": {},
   "source": [
    "Three major tasks:\n",
    "1. Calculates best couples of synset given base and target using nasari.\n",
    "2. Get from BabelNet endpoint three terms maximum associated to the more similar couple of synsets (cosine metric).\n",
    "3. Write on file the result (Columns: Term1 Term2 BS1 BS2 Terms_in_BS1 Terms_in_BS2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a636cc66-52ed-44af-81ff-9b48a563396b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Operation successful\n",
      "Result written in ./utils/result.tsv\n"
     ]
    }
   ],
   "source": [
    "with open(\"utils/result.tsv\", \"w\", encoding=\"utf-8\") as of:\n",
    "    \n",
    "    for i in range(0, len(annotation1)):\n",
    "        \n",
    "        # take the best couple of synset of a couple of terms\n",
    "        (syn_1, syn_2), _ = cosine_similarity_vector(nasari_dict, gold[base[i]], gold[target[i]])\n",
    "        \n",
    "        if syn_1 is not None and syn_2 is not None:\n",
    "            \n",
    "            # inizialize output buffer with 4 columns (base, target, best babel synset1, best babel synset2)\n",
    "            of.write(\"{}\\t{}\\t{}\\t{}\\t\".format(base[i], target[i], syn_1, syn_2))\n",
    "            \n",
    "            # obtain tree terms associated to the synset1 and synset2\n",
    "            terms_1 = get_synset_terms_HTTP(syn_1)\n",
    "            terms_2 = get_synset_terms_HTTP(syn_2)\n",
    "\n",
    "            for term_1 in terms_1:\n",
    "                if term_1 == terms_1[len(terms_1) - 1]:\n",
    "                    # add a column whith the terms in babel synset1 \n",
    "                    of.write(term_1 + \"\\t\") \n",
    "                else:\n",
    "                    of.write(term_1 + \",\") \n",
    "            \n",
    "            for term_2 in terms_2:\n",
    "                if term_2 == terms_2[len(terms_2) - 1]:\n",
    "                     # add a column whith the terms in babel synset2 \n",
    "                    of.write(term_2 + \"\\n\")\n",
    "                else:\n",
    "                    of.write(term_2 + \",\") \n",
    "                    \n",
    "        else:\n",
    "            # write a blank row\n",
    "            of.write(\"{}\\t{}\\tNull\\tNull\\tNull\\tNull\\n\".format(base[i], target[i]))\n",
    "        \n",
    "    print(\"Operation successful\")\n",
    "    print(\"Result written in ./utils/result.tsv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9047e910-ac88-44ab-9487-6e5f4c98e660",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
